{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772d6eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FrankVerhoef/opt/anaconda3/envs/atcs/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from snli_lightning import SNLIModule\n",
    "from models import ENCODER_TYPES\n",
    "from encoder import CLASSIFIER_TYPES\n",
    "from data import SNLIdataset, LABEL_VALUE\n",
    "from vocab import Vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1aff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params for the sentence encoder\n",
    "opt = {\n",
    "    \"data_dir\": \"data/\",\n",
    "    \"dataset_dir\": \"snli_1_0/\",\n",
    "    \"model_dir\": \"models/\",\n",
    "    \"vocab_file\": \"snli_vocab.json\",\n",
    "    \"embeddings_file\": \"glove.840B.300d.txt\",\n",
    "    \"snli_embeddings\": \"glove.snli.300d.txt\",\n",
    "    \"embedding_size\": 300,\n",
    "    \"hidden_size\": 2048,\n",
    "    \"aggregate_method\": \"max\",\n",
    "    \"classifier\": \"mlp\"\n",
    "}\n",
    "\n",
    "LABELS = [k for k, _ in sorted(LABEL_VALUE.items(), key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11ba50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(p, h):\n",
    "\n",
    "    p_ids = torch.tensor([vocab.encode(vocab.tokenize(p))])\n",
    "    h_ids = torch.tensor([vocab.encode(vocab.tokenize(h))])\n",
    "\n",
    "    p = snli_model.enc.embedding(p_ids).float()\n",
    "    h = snli_model.enc.embedding(h_ids).float()\n",
    "    u = snli_model.enc.sentence_encoder(p, [len(p_ids)])\n",
    "    v = snli_model.enc.sentence_encoder(h, [len(h_ids)])\n",
    "    \n",
    "    combined = torch.concat([u, v, abs(u - v), u * v], dim=1).float()\n",
    "    out = snli_model.enc.classifier(combined)\n",
    "    pred = out.argmax(dim=1)[0].item()\n",
    "\n",
    "    return LABELS[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e515a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder type [mean, lstm, bilstm, poolbilstm]: poolbilstm\n",
      "Parameters\n",
      "data_dir            \tdata/\n",
      "dataset_dir         \tsnli_1_0/\n",
      "model_dir           \tmodels/\n",
      "vocab_file          \tsnli_vocab.json\n",
      "embeddings_file     \tglove.840B.300d.txt\n",
      "snli_embeddings     \tglove.snli.300d.txt\n",
      "embedding_size      \t300\n",
      "hidden_size         \t2048\n",
      "aggregate_method    \tmax\n",
      "classifier          \tmlp\n",
      "encoder_type        \tpoolbilstm\n",
      "Loaded vocabulary with 33635 tokens\n",
      "Matching vocab with embeddings from data/snli_1_0/glove.snli.300d.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30348it [00:10, 2877.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30348 embeddings from data/snli_1_0/glove.snli.300d.txt\n",
      "Vocab coverage:  total 33635, common 30348 oov 3287 (9.77%)\n",
      "Corpus coverage: total 12324969, common 12316551 oov 8418 (0.07%)\n",
      "Most frequent out-of-vocabulary tokens:\n",
      "                     \t2187\n",
      "..                   \t78\n",
      "rollerskaters        \t62\n",
      "surfboarder          \t50\n",
      "for$                 \t42\n",
      "graffited            \t40\n",
      "parasailer           \t35\n",
      "men-                 \t33\n",
      "sidewalk-            \t30\n",
      "boogieboard          \t28\n",
      "Load model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get encoder type from user\n",
    "enc = input(\"Encoder type [mean, lstm, bilstm, poolbilstm]: \")\n",
    "assert enc in ENCODER_TYPES, \"Unknown encoder type {}\".format(enc)\n",
    "opt[\"encoder_type\"] = enc\n",
    "\n",
    "print('Parameters')\n",
    "print('\\n'.join([\"{:20}\\t{}\".format(k,v) for k,v in opt.items()]))\n",
    "\n",
    "dataset_dir = opt[\"data_dir\"] + opt[\"dataset_dir\"]\n",
    "\n",
    "# initialize vocab with tokenizer and encoder\n",
    "vocab = Vocab()\n",
    "\n",
    "# get vocabulary from vocabfile\n",
    "vocab_path = dataset_dir + (opt[\"vocab_file\"] if opt[\"vocab_file\"] != None else \"snli_vocab.json\")\n",
    "assert vocab.load(vocab_path), print(\"Cannot load preprocessed vocab\")\n",
    "\n",
    "# read matched embeddings from preprocessed file\n",
    "embed_path = dataset_dir + (opt[\"snli_embeddings\"] if opt[\"snli_embeddings\"] != None else \"glove.snli.300d.txt\")\n",
    "embedding = vocab.match_with_embeddings(path=embed_path, embedding_size=opt[\"embedding_size\"])\n",
    "\n",
    "# load the model\n",
    "print(\"Load model\")\n",
    "snli_model = SNLIModule(embedding=embedding, opt=opt)\n",
    "snli_model.enc.sentence_encoder.load_state_dict(torch.load(opt[\"model_dir\"] + \"encoder_\" + opt[\"encoder_type\"]))\n",
    "snli_model.enc.classifier.load_state_dict(torch.load(opt[\"model_dir\"] + \"classifier_\" + opt[\"encoder_type\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c3db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts:  entailment\n"
     ]
    }
   ],
   "source": [
    "p = \"i am walking in the rain\"\n",
    "h = \"i need an umbrella\"\n",
    "l = predict_one(p, h)\n",
    "print(\"Model predicts: \", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d47c762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts:  neutral\n"
     ]
    }
   ],
   "source": [
    "p = \"the weather is really great\"\n",
    "h = \"many people go to the beach\"\n",
    "l = predict_one(p, h)\n",
    "print(\"Model predicts: \", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9452ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts:  entailment\n"
     ]
    }
   ],
   "source": [
    "p = \"i am walking in the sun\"\n",
    "h = \"it must be winter\"\n",
    "l = predict_one(p, h)\n",
    "print(\"Model predicts: \", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc818c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your own sentences\n",
    "p = input(\"Premise: \")\n",
    "h = input(\"Hypothesis: \")\n",
    "l = predict_one(p, h)\n",
    "print(\"Model predicts: \", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b29a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
